{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7935656,"sourceType":"datasetVersion","datasetId":4664922},{"sourceId":7936293,"sourceType":"datasetVersion","datasetId":4665376},{"sourceId":7936762,"sourceType":"datasetVersion","datasetId":4665732},{"sourceId":7937881,"sourceType":"datasetVersion","datasetId":4666564},{"sourceId":7939011,"sourceType":"datasetVersion","datasetId":4667370}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.applications import VGG16\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras.layers import Dense, Flatten, Dropout\n\nimport numpy as np\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPooling3D, Flatten, Dense, Dropout, Input\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.589746Z","iopub.execute_input":"2024-03-25T15:10:18.590432Z","iopub.status.idle":"2024-03-25T15:10:18.599153Z","shell.execute_reply.started":"2024-03-25T15:10:18.590394Z","shell.execute_reply":"2024-03-25T15:10:18.598025Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Load the dataset into a DataFrame\ndataset_path = '/kaggle/input/vodhdataset/sampled_dataset_with_images_vodh (1).csv'\n\ndf = pd.read_csv(dataset_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.601107Z","iopub.execute_input":"2024-03-25T15:10:18.601353Z","iopub.status.idle":"2024-03-25T15:10:18.640738Z","shell.execute_reply.started":"2024-03-25T15:10:18.601332Z","shell.execute_reply":"2024-03-25T15:10:18.639915Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.641781Z","iopub.execute_input":"2024-03-25T15:10:18.642046Z","iopub.status.idle":"2024-03-25T15:10:18.649226Z","shell.execute_reply.started":"2024-03-25T15:10:18.642024Z","shell.execute_reply":"2024-03-25T15:10:18.648246Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"df['image_matrix'][2]","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.651222Z","iopub.execute_input":"2024-03-25T15:10:18.651517Z","iopub.status.idle":"2024-03-25T15:10:18.661189Z","shell.execute_reply.started":"2024-03-25T15:10:18.651477Z","shell.execute_reply":"2024-03-25T15:10:18.660258Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'[[[255 253 255]\\n  [255 254 255]\\n  [254 255 251]\\n  ...\\n  [253 255 251]\\n  [255 255 254]\\n  [255 255 255]]\\n\\n [[255 253 255]\\n  [252 249 251]\\n  [254 255 251]\\n  ...\\n  [251 255 249]\\n  [255 255 252]\\n  [254 255 253]]\\n\\n [[254 253 255]\\n  [255 255 255]\\n  [255 255 254]\\n  ...\\n  [255 255 251]\\n  [250 254 248]\\n  [253 255 251]]\\n\\n ...\\n\\n [[253 254 255]\\n  [253 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 252]\\n  [255 255 252]\\n  [255 255 251]]\\n\\n [[251 254 255]\\n  [253 254 255]\\n  [252 254 255]\\n  ...\\n  [253 252 254]\\n  [255 251 255]\\n  [255 253 255]]\\n\\n [[251 254 255]\\n  [251 254 255]\\n  [253 254 255]\\n  ...\\n  [255 253 255]\\n  [255 252 255]\\n  [255 250 255]]]'"},"metadata":{}}]},{"cell_type":"code","source":"type(df['image_matrix'][2])","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.662287Z","iopub.execute_input":"2024-03-25T15:10:18.662599Z","iopub.status.idle":"2024-03-25T15:10:18.671929Z","shell.execute_reply.started":"2024-03-25T15:10:18.662575Z","shell.execute_reply":"2024-03-25T15:10:18.671053Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}]},{"cell_type":"code","source":"# Define a function to convert the string representation of image matrices to actual NumPy arrays\ndef convert_to_array(string_matrix):\n    # Remove newline characters and square brackets\n    string_matrix = string_matrix.replace('\\n', '').replace('[', '').replace(']', '')\n    # Split the string by whitespace and convert to integers\n    pixel_values = [int(value) for value in string_matrix.split() if value.isdigit()]\n    # Convert to NumPy array\n    return np.array(pixel_values)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.673123Z","iopub.execute_input":"2024-03-25T15:10:18.673651Z","iopub.status.idle":"2024-03-25T15:10:18.681650Z","shell.execute_reply.started":"2024-03-25T15:10:18.673621Z","shell.execute_reply":"2024-03-25T15:10:18.680874Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df['image_matrix'] = df['image_matrix'].apply(convert_to_array)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.682659Z","iopub.execute_input":"2024-03-25T15:10:18.682925Z","iopub.status.idle":"2024-03-25T15:10:18.818144Z","shell.execute_reply.started":"2024-03-25T15:10:18.682903Z","shell.execute_reply":"2024-03-25T15:10:18.817257Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df['image_matrix']","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.819178Z","iopub.execute_input":"2024-03-25T15:10:18.819434Z","iopub.status.idle":"2024-03-25T15:10:18.832382Z","shell.execute_reply.started":"2024-03-25T15:10:18.819413Z","shell.execute_reply":"2024-03-25T15:10:18.831423Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0       [224, 224, 224, 224, 224, 224, 223, 223, 223, ...\n1       [171, 188, 209, 170, 187, 208, 168, 187, 208, ...\n2       [255, 253, 255, 255, 254, 255, 254, 255, 251, ...\n3       [0, 1, 11, 0, 1, 11, 0, 1, 11, 0, 1, 11, 0, 1,...\n4       [226, 167, 98, 226, 167, 98, 224, 166, 100, 20...\n                              ...                        \n2609    [1, 1, 2, 2, 2, 3, 5, 5, 4, 2, 2, 3, 2, 3, 3, ...\n2610    [120, 54, 13, 99, 34, 0, 96, 33, 0, 26, 18, 18...\n2611    [11, 31, 78, 11, 31, 78, 11, 31, 78, 34, 39, 7...\n2612    [228, 225, 227, 229, 226, 228, 229, 226, 228, ...\n2613    [34, 19, 16, 34, 19, 16, 34, 19, 16, 34, 20, 2...\nName: image_matrix, Length: 2614, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Check the sizes of the image arrays\nsizes = df['image_matrix'].apply(lambda x: x.size)\nunique_sizes = sizes.unique()\nprint(\"Unique sizes of image arrays:\", unique_sizes)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.836290Z","iopub.execute_input":"2024-03-25T15:10:18.836990Z","iopub.status.idle":"2024-03-25T15:10:18.845106Z","shell.execute_reply.started":"2024-03-25T15:10:18.836967Z","shell.execute_reply":"2024-03-25T15:10:18.844286Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Unique sizes of image arrays: [108]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a function to resize the image arrays\ndef resize_image_array(image_array):\n    # Reshape the image array to a 3D array (height, width, channels)\n    image_array = np.array(image_array).reshape((int(len(image_array) / 3), 3))\n    \n    # Resize the image array to (224, 224) using PIL\n    image = Image.fromarray(image_array.astype('uint8'))\n    resized_image = image.resize((224, 224))\n    \n    # Convert the resized image to a NumPy array\n    resized_image_array = np.array(resized_image)\n    \n    # Add a third dimension representing the channels\n    resized_image_array = np.expand_dims(resized_image_array, axis=2)\n    \n    # Stack the array along the third dimension to create (224, 224, 3)\n    resized_image_array = np.tile(resized_image_array, (1, 1, 3))\n    \n    return resized_image_array","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.846005Z","iopub.execute_input":"2024-03-25T15:10:18.846268Z","iopub.status.idle":"2024-03-25T15:10:18.854064Z","shell.execute_reply.started":"2024-03-25T15:10:18.846236Z","shell.execute_reply":"2024-03-25T15:10:18.853174Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"df['resized_image_array'] = df['image_matrix'].apply(resize_image_array)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:18.855029Z","iopub.execute_input":"2024-03-25T15:10:18.855295Z","iopub.status.idle":"2024-03-25T15:10:20.691660Z","shell.execute_reply.started":"2024-03-25T15:10:18.855273Z","shell.execute_reply":"2024-03-25T15:10:20.690590Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df['resized_image_array'].head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:20.692945Z","iopub.execute_input":"2024-03-25T15:10:20.693364Z","iopub.status.idle":"2024-03-25T15:10:28.790037Z","shell.execute_reply.started":"2024-03-25T15:10:20.693329Z","shell.execute_reply":"2024-03-25T15:10:28.789084Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"0    [[[224, 224, 224], [224, 224, 224], [224, 224,...\n1    [[[169, 169, 169], [169, 169, 169], [169, 169,...\n2    [[[255, 255, 255], [255, 255, 255], [255, 255,...\n3    [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n4    [[[233, 233, 233], [233, 233, 233], [233, 233,...\nName: resized_image_array, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Shape of image data:\", df['resized_image_array'][3].shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:28.791168Z","iopub.execute_input":"2024-03-25T15:10:28.791435Z","iopub.status.idle":"2024-03-25T15:10:28.796747Z","shell.execute_reply.started":"2024-03-25T15:10:28.791411Z","shell.execute_reply":"2024-03-25T15:10:28.795821Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Shape of image data: (224, 224, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a mapping for the labels\nlabel_mapping = {\"TRUE\": 1, \"Fake\": 0}\n\n# Convert string labels to integer labels\nlabel_encoder = LabelEncoder()\ninteger_labels = label_encoder.fit_transform(df['Label'].map(label_mapping))\ndf['Label'] = integer_labels","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:28.797753Z","iopub.execute_input":"2024-03-25T15:10:28.798009Z","iopub.status.idle":"2024-03-25T15:10:28.810607Z","shell.execute_reply.started":"2024-03-25T15:10:28.797987Z","shell.execute_reply":"2024-03-25T15:10:28.809714Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into features (X) and labels (y)\nX = np.array(df['resized_image_array'].tolist())  # Features  \ny = (df['Label'])","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:28.811640Z","iopub.execute_input":"2024-03-25T15:10:28.811964Z","iopub.status.idle":"2024-03-25T15:10:28.937014Z","shell.execute_reply.started":"2024-03-25T15:10:28.811933Z","shell.execute_reply":"2024-03-25T15:10:28.936199Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of image data:\", X[3].shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:28.938139Z","iopub.execute_input":"2024-03-25T15:10:28.938440Z","iopub.status.idle":"2024-03-25T15:10:28.943716Z","shell.execute_reply.started":"2024-03-25T15:10:28.938415Z","shell.execute_reply":"2024-03-25T15:10:28.942618Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Shape of image data: (224, 224, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:28.944875Z","iopub.execute_input":"2024-03-25T15:10:28.945151Z","iopub.status.idle":"2024-03-25T15:10:29.069203Z","shell.execute_reply.started":"2024-03-25T15:10:28.945129Z","shell.execute_reply":"2024-03-25T15:10:29.068306Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of image data:\", X_train[3].shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:29.070344Z","iopub.execute_input":"2024-03-25T15:10:29.070678Z","iopub.status.idle":"2024-03-25T15:10:29.075568Z","shell.execute_reply.started":"2024-03-25T15:10:29.070653Z","shell.execute_reply":"2024-03-25T15:10:29.074553Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Shape of image data: (224, 224, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pre-trained VGG16 model without top (fully connected layers)\nvgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the convolutional base\nvgg_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:29.076770Z","iopub.execute_input":"2024-03-25T15:10:29.077064Z","iopub.status.idle":"2024-03-25T15:10:29.357766Z","shell.execute_reply.started":"2024-03-25T15:10:29.077041Z","shell.execute_reply":"2024-03-25T15:10:29.356879Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new model\nmodel = Sequential([\n    vgg_model,  # Use pre-trained VGG16 as convolutional base\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dense(1, activation='sigmoid')  # Use sigmoid activation for binary classification\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:29.359021Z","iopub.execute_input":"2024-03-25T15:10:29.359357Z","iopub.status.idle":"2024-03-25T15:10:29.371551Z","shell.execute_reply.started":"2024-03-25T15:10:29.359331Z","shell.execute_reply":"2024-03-25T15:10:29.370734Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Train the model using the fit method with validation data\nmodel.fit(X_train, y_train, epochs=4, batch_size=32, validation_data=(X_val, y_val))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:29.372936Z","iopub.execute_input":"2024-03-25T15:10:29.373398Z","iopub.status.idle":"2024-03-25T15:11:13.686890Z","shell.execute_reply.started":"2024-03-25T15:10:29.373368Z","shell.execute_reply":"2024-03-25T15:11:13.685967Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Epoch 1/4\n\u001b[1m 1/66\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 2s/step - accuracy: 0.2188 - loss: 4.6808","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1711379432.349472     383 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7632 - loss: 9.4644","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1711379440.654187     383 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1711379441.572348     386 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 174ms/step - accuracy: 0.7638 - loss: 9.3951 - val_accuracy: 0.8451 - val_loss: 1.2103\nEpoch 2/4\n\u001b[1m 1/66\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.8125 - loss: 2.2299","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1711379443.769867     384 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.8749 - loss: 0.6831 - val_accuracy: 0.8394 - val_loss: 1.0085\nEpoch 3/4\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.8825 - loss: 0.4395 - val_accuracy: 0.7935 - val_loss: 0.8900\nEpoch 4/4\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.9152 - loss: 0.2932 - val_accuracy: 0.8356 - val_loss: 0.9614\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ec9c92c7e50>"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(X_val, y_val)\nprint(f'Test accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:11:13.687976Z","iopub.execute_input":"2024-03-25T15:11:13.688280Z","iopub.status.idle":"2024-03-25T15:11:15.895881Z","shell.execute_reply.started":"2024-03-25T15:11:13.688256Z","shell.execute_reply":"2024-03-25T15:11:15.894931Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.8348 - loss: 0.9600\nTest accuracy: 0.8355640769004822\n","output_type":"stream"}]}]}